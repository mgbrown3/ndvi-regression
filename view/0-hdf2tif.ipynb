{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook to extract NDVI, LandCover and Precipitation (Step 0)\n",
    "Date sources: <br>\n",
    "/css/modis/Collection6/L3/MOD13Q1-Vegetation\n",
    "/css/modis/Collection6/L3/MCD12Q1-Landcover\n",
    "/css/imerg/daily_Late_V06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import datetime\n",
    "from osgeo import gdal\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hdf_sds_to_tif(in_hdf, out_tif, key=\"NDVI\"):\n",
    "    # input hdf (absolute path) \n",
    "    # extract subdataset and export as geoTiff\n",
    "\n",
    "    hdf = gdal.Open(in_hdf)\n",
    "    sdsdict = hdf.GetMetadata(\"SUBDATASETS\")\n",
    "    sdslist =[sdsdict[k] for k in sdsdict.keys() if '_NAME' in k]\n",
    "    \n",
    "    #search for target layer in hdf\n",
    "    layer = [i for i in sdslist if key in i]\n",
    "    \n",
    "    # process \n",
    "    if layer:\n",
    "        cmd = f\"gdal_translate {layer[0]} {out_tif}\"\n",
    "        os.system(cmd)\n",
    "    else:\n",
    "        raise RuntimeError(f'Can not find {key} in {in_hdf}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dirs of input datasets\n",
    "ndvi_dirn = \"/css/modis/Collection6/L3/MOD13Q1-Vegetation\"\n",
    "lc_dirn = \"/css/modis/Collection6/L3/MCD12Q1-Landcover\"\n",
    "pr_dirn = \"/css/imerg/daily_Late_V06\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dirs of output datasets\n",
    "ndvi_out_dirn = \"/att/nobackup/jli30/workspace/ndvi_MGBrown_notebooks/data/test_out/NDVI\"\n",
    "pr_out_dirn = \"/att/nobackup/jli30/workspace/ndvi_MGBrown_notebooks/data/test_out/PRECIP\"\n",
    "lc_out_dirn = \"/att/nobackup/jli30/workspace/ndvi_MGBrown_notebooks/data/test_out/LANDCOVER\"\n",
    "\n",
    "# create dirs if not exist\n",
    "if not os.path.exists(ndvi_out_dirn):\n",
    "    os.mkdir(ndvi_out_dirn)\n",
    "if not os.path.exists(pr_out_dirn):\n",
    "    os.mkdir(pr_out_dirn)    \n",
    "if not os.path.exists(lc_out_dirn):\n",
    "    os.mkdir(lc_out_dirn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2006\n",
    "tile = \"h16v07\" # target tile index\n",
    "days = np.arange(1,365,16) # MOD13 freq \n",
    "\n",
    "vihis = 5 # past 5 years NDVI\n",
    "tint = 30 # past 30 days Precip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([81])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "days[5:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Date:  2006-03-22 00:00:00\n",
      "Input file size is 4800, 4800\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 4800, 4800\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 4800, 4800\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 4800, 4800\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 4800, 4800\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 4800, 4800\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 1800, 3600\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 1800, 3600\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 1800, 3600\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 1800, 3600\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 1800, 3600\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 1800, 3600\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 1800, 3600\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 1800, 3600\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 1800, 3600\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 1800, 3600\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 1800, 3600\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 1800, 3600\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 1800, 3600\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 1800, 3600\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 1800, 3600\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 1800, 3600\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 1800, 3600\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 1800, 3600\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 1800, 3600\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 1800, 3600\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 1800, 3600\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 1800, 3600\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 1800, 3600\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 1800, 3600\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 1800, 3600\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 1800, 3600\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 1800, 3600\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 1800, 3600\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 1800, 3600\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 1800, 3600\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 1800, 3600\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 2400, 2400\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "CPU times: user 1.56 s, sys: 930 ms, total: 2.49 s\n",
      "Wall time: 41.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#loop through days\n",
    "for day in days[5:6]:\n",
    "    \n",
    "    yj = str(year)+str(day).zfill(3)\n",
    "    c_date = datetime.datetime.strptime(yj, \"%Y%j\")\n",
    "    print(\"Current Date: \", c_date)\n",
    "    \n",
    "    #--------------------------------------------------------------------------\n",
    "    # Extract NDVI\n",
    "    #--------------------------------------------------------------------------\n",
    "    # form a list containing current and past 5-yr MOD13-veg files\n",
    "    ndvi_date_p = [c_date.replace(year=c_date.year-i) for i in range(vihis+1)]   \n",
    "    ndvi_f_list = []\n",
    "    for d in ndvi_date_p:\n",
    "        yyyy = str(d.year)\n",
    "        ddd = str(day).zfill(3)\n",
    "        path = os.path.join(ndvi_dirn,\n",
    "                           yyyy,\n",
    "                           ddd,\n",
    "                           f\"*{tile}*.hdf\")\n",
    "        f = glob.glob(path)\n",
    "        ndvi_f_list.append(f[0])\n",
    "    # convert subdataset to geoTiff\n",
    "    for f in ndvi_f_list:\n",
    "        fn = os.path.basename(f)\n",
    "        fn = os.path.splitext(fn)[0]+\".ndvi.tif\"\n",
    "        ofile = os.path.join(ndvi_out_dirn, fn)\n",
    "    \n",
    "        if not os.path.exists(ofile):\n",
    "            hdf_sds_to_tif(f, ofile)\n",
    "    #--------------------------------------------------------------------------\n",
    "    # Extract Precip\n",
    "    #--------------------------------------------------------------------------\n",
    "    # for a list containing current and past 30-day precip files\n",
    "    pr_date_p = [c_date-datetime.timedelta(days=i) for i in range(tint+1)]\n",
    "    pr_f_list = []\n",
    "    for d in pr_date_p:\n",
    "        yyyy = str(d.year)\n",
    "        tstamp = datetime.datetime.strftime(d, \"%Y%m%d\")\n",
    "        path = os.path.join(pr_dirn,\n",
    "                           yyyy,\n",
    "                           f\"*.{tstamp}*.nc4\")\n",
    "        f = glob.glob(path)\n",
    "        pr_f_list.append(f[0])\n",
    "    # convert subdataset to geoTiff\n",
    "    for f in pr_f_list:\n",
    "        fn = os.path.basename(f)\n",
    "        fn = os.path.splitext(fn)[0]+\".precip.tif\"\n",
    "        ofile = os.path.join(pr_out_dirn, fn)\n",
    "    \n",
    "        if not os.path.exists(ofile):\n",
    "            hdf_sds_to_tif(f, ofile, key=\"precipitationCal\")\n",
    "    \n",
    "    #--------------------------------------------------------------------------\n",
    "    # Extract LandCover\n",
    "    #--------------------------------------------------------------------------\n",
    "    # LandCover 1 file per year\n",
    "    path = os.path.join(lc_dirn,\n",
    "                   str(year),\n",
    "                   \"001\",\n",
    "                   f\"*{str(year)}001*{tile}*.hdf\")\n",
    "    f = glob.glob(path)[0]\n",
    "    \n",
    "    # convert subdataset to geoTiff\n",
    "    fn = os.path.basename(f)\n",
    "    fn = os.path.splitext(fn)[0]+\".landcover.tif\"        \n",
    "    ofile = os.path.join(lc_out_dirn, fn)\n",
    "    \n",
    "    if not os.path.exists(ofile):\n",
    "        hdf_sds_to_tif(f, ofile, key=\"LC_Type1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-ndvi-nb-env]",
   "language": "python",
   "name": "conda-env-.conda-ndvi-nb-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
